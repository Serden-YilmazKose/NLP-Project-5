{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efe489c-6970-4856-91ea-7a2678dff0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import genesis\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517cca5-1976-49d4-bc3b-2a94fb944a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('genesis')\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d635285-a473-4424-b307-b2d66d5a64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"./kurrek.2020.slur-corpus.csv\"\n",
    "data = pd.read_csv(path, sep=\",\", header = 0, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5565270-e765-475e-84b6-89c552e0b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to check if string contains any element from a string\n",
    "# https://bobbyhadz.com/blog/python-check-if-string-contains-element-from-list\n",
    "def is_element_in_string(string, flist):\n",
    "    if any((match := substring) in string for substring in flist):\n",
    "        print('The string contains at least one element from the list')\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5093049e-92f5-4852-b6d0-f06ab37749a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Body: fuck that i dont wanna watch [REDACTED] porn. \n",
      "\n",
      "Index: 5000\n",
      "Body: if i took them to the forums chances are sergei would call me a [REDACTED] or one of the mods would ban me for speaking ill of the game, reddit i feel is the only place i feel i can critique the game safely.\n",
      "\n",
      "Index: 10000\n",
      "Body: good idea.  let's just all talk online about it, and ignore it in the real world.  things will definitely change, then.\n",
      "\n",
      "eat a dick you [REDACTED] ass bitch.\n",
      "\n",
      "Index: 15000\n",
      "Body: ayyy boo-boo, it's time to lynch us a [REDACTED]\n",
      "\n",
      "Index: 20000\n",
      "Body: yeah, the [REDACTED] work song has really made a comeback in the last few years.\n",
      "\n",
      "Index: 25000\n",
      "Body: nah, add in \"faggot\" \"cuck\" and \"sand [REDACTED]\" then you have a t_d spam post. \n",
      "\n",
      "Index: 30000\n",
      "Body: yea, cause it would have taken him up to that point to realize you just spelled out [REDACTED]. \n",
      "\n",
      "Index: 35000\n",
      "Body: good on /u/randsfoodstamps for calling them out about \"violent\" people. seriously, /r/libertarian has a huge crossover with /r/theredpill, /r/conspiracy, /r/whiterights, /r/mensrights, and /r/[REDACTED]s.\n",
      "\n",
      "Index: 40000\n",
      "Body: what did you expect?? when they banned /r/[REDACTED]s, their users were never gone, they just flooded into the defaults.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace slur with [REDACTED], and print\n",
    "# Make new data list using pandas\n",
    "# This one is only to print the strings, to avoid printing harmful language. \n",
    "\n",
    "path = \"./kurrek.2020.slur-corpus.csv\"\n",
    "redacted_data = pd.read_csv(path, sep=\",\", header = 0, on_bad_lines='skip')\n",
    "\n",
    "# Iterate for each index in redacted_data, and modify the 'body' to replace the \n",
    "# slur with [REDACTED]. The indexes will remain the same as the one found in the original\n",
    "# document, so this is really to just print out certain rows whilst avoiding printing out the\n",
    "# harmful language (the slurs).\n",
    "for index, row in redacted_data.iterrows():\n",
    "    T1, T2 = str(row['body']), str(row['slur'])\n",
    "    redacted_data.at[index, 'body'] = T1.lower().replace(T2, \"[REDACTED]\")\n",
    "    # print a couple to show it works:\n",
    "    if index % 5000 == 0:\n",
    "        print(f\"Index: {index}\\nBody: {redacted_data.at[index, 'body']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b13a32-7cea-4da1-960b-f841ddc776f7",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8303123-f3ba-4e6f-9177-b7c8d9aca126",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"By constructing a dataframe of posts assigned to the same category, suggest a script that outputs the\n",
    "vocabulary set of each category, the size of the vocabulary, the total number of tokens, the average\n",
    "number of tokens per post and its standard deviation, the average number of pronouns per post and the\n",
    "associated standard deviation, the ten most frequent tokens in each category, excluding the stopword list.\n",
    "Represent the statistical result in a clear table and discuss whether some parameters are most relevant to\n",
    "discriminate a given category.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb95173-a520-4d54-88dd-56335f38f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is a list of categories, and the number of frequencies\n",
    "\"\"\"\n",
    "DEG \tDerogatory \t20531\n",
    "NDG \tNon Derogatory Non Appropriative \t16729\n",
    "HOM \tHomonym \t1998\n",
    "APR \tAppropriative \t553\n",
    "CMP \tNoise \t189\n",
    "\"\"\"\n",
    "# Create dictionary variables to store data stored about each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0b04e-eee1-4bfd-8f5c-d8897cf8e69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7d849-6892-4359-9ed2-26ed62d3ee3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
